## 2.1 아키텍처 개요

두 I/O 모델의  비교를 위해 동일한 기능을 수행하는 두 개의 서버를 각각 `epoll`과 `io_uring`을 사용하여 구현하였습니다.

- 클라이언트 연결 수락 및 관리
- 패킷 수신 및 데이터 처리
- 처리된 결과 응답 전송
- 클라이언트 연결 종료 처리

## 2.2  핵심 클래스 구조

### 2.2.1. I/O 관리 클래스

#### 2.2.1.1 `EPoll`

- **역할:** epoll 기반 I/O 이벤트 처리를 담당하는 클래스입니다. 소켓 파일 디스크립터를 등록/수정/삭제하고, 이벤트를 모니터링하며, 준비된 이벤트를 처리합니다.
- **주요 멤버 및 기능:**
    - `epoll_fd_`: epoll 인스턴스의 파일 디스크립터
    - `events_`: 이벤트 결과를 저장하는 벡터
    - `buffer_manager_`: 버퍼 관리를 위한 EPollBuffer 인스턴스
    - `addEvent()`: 파일 디스크립터를 epoll에 등록
    - `modifyEvent()`: 등록된 이벤트 속성 수정
    - `removeEvent()`: 파일 디스크립터를 epoll에서 제거
    - `waitForEvents()`: 이벤트 발생 대기 (epoll_wait 호출)
    - `getEvents()`: 발생한 이벤트 반환
    
- **코드 예시 (이벤트 대기 및 처리):**
```cpp
int EPoll::waitForEvents(int timeout_ms) {
    if (!epoll_initialized_) {
        return -1;
    }
    
    num_events_ = epoll_wait(epoll_fd_, events_.data(), MAX_EVENTS, timeout_ms);
    current_event_ = 0;
    return num_events_;
}

int EPoll::getEvents(epoll_event* events, int max_events) {
    if (!events || max_events <= 0) {
        return 0;
    }
    
    int count = 0;
    while (current_event_ < num_events_ && count < max_events) {
        events[count++] = events_[current_event_++];
    }
    
    return count;
}```
#### 2.2.1.2 `IOUring`

- **역할:** io_uring 기반 I/O 이벤트 처리를 담당하는 클래스입니다. 커널과 공유하는 제출 큐(SQ)와 완료 큐(CQ)를 관리하고, 비동기 I/O 요청을 처리합니다.
- **주요 멤버 및 기능:**
    - `ring_`: io_uring 인스턴스
    - `buffer_manager_`: 버퍼 관리를 위한 UringBuffer 인스턴스
    - `prepareAccept()`: 연결 수락 작업 준비
    - `prepareRead()`: 읽기 작업 준비
    - `prepareWrite()`: 쓰기 작업 준비
    - `prepareClose()`: 종료 작업 준비
    - `submitAndWait()`: 작업 제출 및 완료 대기
    - `peekCQE()`: 완료 큐에서 완료된 작업 확인
    
- **코드 예시 (I/O 요청 제출):**
```cpp
void IOUring::prepareAccept(int socket_fd) {
    io_uring_sqe* sqe = getSQE();
    setContext(sqe, OperationType::ACCEPT, -1, 0);
    const int flags = 0;
    io_uring_prep_multishot_accept(sqe, socket_fd, nullptr, 0, flags);
}

int IOUring::submitAndWait() {
    int ret = io_uring_submit_and_wait(&ring_, NUM_WAIT_ENTRIES);
    if (ret < 0) {
        if (ret != -EINTR) {
            LOG_ERROR("io_uring_submit_and_wait failed: ", ret);
        }
        return ret;
    }
    return 0;
}
```

### 2.2.2 버퍼 관리 클래스

#### 2.2.2.1 `EPollBuffer`

- **역할:** epoll 기반 서버에서 메모리 버퍼 풀을 관리하는 클래스입니다. I/O 작업에 사용될 버퍼를 할당하고 관리합니다.
- **주요 멤버 및 기능:**
    - `buffer_pool_`: 버퍼 메모리 풀
    - `free_buffers_`: 사용 가능한 버퍼 인덱스 리스트
    - `client_buffers_`: 클라이언트별 버퍼 큐
    - `allocateBuffer()`: 버퍼 할당
    - `releaseBuffer()`: 버퍼 해제
    - `readToBuffer()`: 소켓에서 버퍼로 데이터 읽기
    - `writeFromBuffer()`: 버퍼에서 소켓으로 데이터 쓰기

- **코드 예시 (버퍼 할당 및 해제):**
```cpp

IOBuffer EPollBuffer::allocateBuffer() {
    std::lock_guard<std::mutex> lock(buffer_mutex_);
    if (free_buffers_.empty()) {
        LOG_WARN("No free buffers available");
        return IOBuffer(); // 빈 버퍼 반환
    }
    
    int buffer_id = free_buffers_.front();
    free_buffers_.pop_front();
    
    return IOBuffer(buffer_pool_[buffer_id], buffer_id);
}

void EPollBuffer::releaseBuffer(int buffer_id) {
    if (buffer_id < 0 || buffer_id >= static_cast<int>(buffer_pool_.size())) {
        LOG_ERROR("Invalid buffer index: ", buffer_id);
        return;
    }
    
    std::lock_guard<std::mutex> lock(buffer_mutex_);
    free_buffers_.push_back(buffer_id);
}
```
#### 2.2.2.2 `UringBuffer`

- **역할:** io_uring 버퍼 풀을 관리하는 클래스입니다. 커널과 공유하는 메모리 영역에 버퍼 풀을 생성하고 초기화하며, 버퍼 할당 및 해제 기능을 제공합니다. `IOUring` 클래스에 의해 소유됩니다.
- **주요 멤버 및 기능:**
    - `ring_`: `io_uring` 인스턴스에 대한 포인터 (소유권 없음)
    - `buf_ring_`: io_uring 버퍼 링 구조체 포인터
    - `buffer_base_addr_`: 버퍼 풀 메모리 시작 주소
    - `initBufferRing()`: 버퍼 링 초기화 및 메모리 할당
    - `releaseBuffer()`: 사용 완료된 버퍼를 버퍼 링에 반환
    - `getBufferAddr()`: 버퍼 인덱스를 기반으로 버퍼 주소 반환
    - `getBaseAddr()`: 버퍼 풀 메모리 시작 주소 반환

- **코드 예시 (버퍼 링 초기화):**
```cpp
void UringBuffer::initBufferRing() {
    // 버퍼 링을 위한 메모리 할당
    void* ring_addr = mmap(nullptr, ring_size_, 
                          PROT_READ | PROT_WRITE,
                          MAP_ANONYMOUS | MAP_PRIVATE,
                          -1, 0);
    if (ring_addr == MAP_FAILED) {
        throw std::runtime_error("Failed to allocate memory for buffer ring");
    }

    // io_uring에 버퍼 링 등록
    io_uring_buf_reg reg{};
    reg.ring_addr = reinterpret_cast<__u64>(ring_addr);
    reg.ring_entries = NUM_IO_BUFFERS;
    reg.bgid = 1;  // 버퍼 그룹 ID

    int reg_result = io_uring_register_buf_ring(ring_, &reg, 0);
    if (reg_result < 0) {
        munmap(ring_addr, ring_size_);
        throw std::runtime_error("Failed to register buffer ring with io_uring");
    }

    // 버퍼 링 초기화
    buf_ring_ = static_cast<io_uring_buf_ring*>(ring_addr);
    io_uring_buf_ring_init(buf_ring_);
    buffer_base_addr_ = get_buffer_base_addr(ring_addr);
    
    // 모든 버퍼를 링에 추가
    for (uint16_t i = 0; i < NUM_IO_BUFFERS; ++i) {
        uint8_t* buf_addr = getBufferAddr(i, buffer_base_addr_);
        io_uring_buf_ring_add(buf_ring_, buf_addr, IO_BUFFER_SIZE, i,
                            io_uring_buf_ring_mask(NUM_IO_BUFFERS), i);
    }
    
    // 모든 버퍼 등록 완료 표시
    io_uring_buf_ring_advance(buf_ring_, NUM_IO_BUFFERS);
}
```


**메모리 관리 방식:**

- **EPollBuffer**: 사용자 공간의 메모리를 관리하며, 각 I/O 작업 시 커널 공간으로 데이터 복사가 필요합니다.
- **UringBuffer**: 커널과 공유하는 메모리 영역을 사용하여 데이터 복사 오버헤드를 최소화합니다.


### 2.2.3 세션 관리 클래스

#### 2.2.3.1`Session` (epoll 구현과 io_uring 구현)

- **역할:** 클라이언트 연결 및 통신을 관리하는 클래스입니다. 클라이언트 소켓을 추가/제거하고, 메시지 처리 및 이벤트 루프를 실행합니다.
- **공통 멤버 및 기능:**
    - `session_id_`: 세션 식별자
    - `client_sockets_`: 클라이언트 소켓 맵
    - `addClient()`: 클라이언트 추가
    - `removeClient()`: 클라이언트 제거
    - `processEvents()`: 이벤트 처리 루프 실행
    - `sendMessage()`: 클라이언트에게 메시지 전송

- **epoll 버전 코드 예시:**
```cpp
bool Session::processEvents(int timeout_ms) {
    if (client_sockets_.empty()) {
        return false;
    }
    
    // EPoll 이벤트 대기
    int num_events = epoll_->waitForEvents(50);  // 50ms 타임아웃
    
    if (num_events < 0) {
        if (errno == EINTR) {
            return false;
        }
        LOG_ERROR("[Session ", session_id_, "] waitForEvents failed: ", strerror(errno));
        return false;
    } else if (num_events == 0) {
        return false;
    }
    
    // 이벤트 처리
    epoll_event events[EPoll::MAX_EVENTS];
    int event_count = epoll_->getEvents(events, EPoll::MAX_EVENTS);
    
    for (int i = 0; i < event_count; ++i) {
        int client_fd = events[i].data.fd;
        // 생략: 이벤트 타입에 따른 처리
    }
    
    return true;
}
```

- **io_uring 버전 코드 예시:**
```cpp
bool Session::processEvents() {
    if (client_sockets_.empty() || !io_ring_) {
        return false;
    }
    
    unsigned num_cqes = io_ring_->peekCQE(cqes_);
    
    if (num_cqes == 0) {
        const int result = io_ring_->submitAndWait();
        if (result < 0) {
            LOG_ERROR("[Session ", session_id_, "] io_uring_submit_and_wait failed: ", result);
            return false;
        }
        num_cqes = io_ring_->peekCQE(cqes_);
    }
    
    for (unsigned i = 0; i < num_cqes; ++i) {
        io_uring_cqe* cqe = cqes_[i];
        Operation ctx = getContext(cqe);
        
        // 생략: 이벤트 타입에 따른 처리
    }
    
    io_ring_->advanceCQ(num_cqes);
    io_ring_->submit();
    return true;
}
```

**이벤트 처리 방식:**

- **epoll 구현**: `epoll_wait()`를 호출하여 이벤트 발생을 기다린 후, 발생한 이벤트 타입에 따라 `handleRead()`, `handleWrite()` 등의 핸들러를 호출합니다.
- **io_uring 구현**: 완료 큐를 확인하여 완료된 작업을 처리하고, 새로운 작업을 제출 큐에 추가합니다. 작업 타입에 따라 적절한 핸들러를 호출합니다.

**I/O 효율성:**

- **epoll 구현**: 각 I/O 작업마다 시스템 콜을 호출하므로, 다수의 클라이언트를 처리할 때 오버헤드가 발생할 수 있습니다.
- **io_uring 구현**: 여러 I/O 작업을 모아서 한 번에 처리할 수 있으며, 시스템 콜 횟수를 최소화하여 효율성을 높입니다.

#### 2.2.3.2 `SessionManager`

- **역할:** 여러 세션을 관리하고, 클라이언트를 적절한 세션에 할당하는 싱글톤 클래스입니다. 세션별로 워커 스레드를 생성하여 병렬 처리를 지원합니다.
- **주요 멤버 및 기능:**
    - `sessions_`: 세션 ID를 키로 하는 세션 맵
    - `client_sessions_`: 클라이언트 FD를 키로 하는 세션 ID 맵
    - `session_threads_`: 세션별 워커 스레드 맵
    - `initialize()`: 세션 매니저 초기화
    - `start()`: 세션별 워커 스레드 시작
    - `stop()`: 세션별 워커 스레드 종료
    - `assignClientToSession()`: 클라이언트를 세션에 할당
    - `sessionWorker()`: 세션 워커 스레드 함수
- **코드 예시 (세션 워커 스레드):**

```cpp
void SessionManager::sessionWorker(std::shared_ptr<Session> session) {
    if (!session) {
        LOG_ERROR("[SessionManager] Null session passed to sessionWorker");
        return;
    }

    const int32_t session_id = session->getSessionId();
    LOG_INFO("[SessionManager] Session ", session_id, " worker thread started");
    
    try {
        while (running_ && !should_terminate_) {
            // 세션이 비어있으면 대기
            if (session->getClientCount() == 0) {
                std::this_thread::sleep_for(std::chrono::milliseconds(100));
                continue;
            }
            
            try {
                // 세션 이벤트 처리
                session->processEvents(100);
            } catch (const std::exception& e) {
                LOG_ERROR("[SessionManager] Exception in session ", session_id, 
                          " processEvents: ", e.what());
                std::this_thread::sleep_for(std::chrono::milliseconds(100));
            }
        }
    } catch (const std::exception& e) {
        LOG_ERROR("[SessionManager] Fatal exception in session ", session_id, 
                 " worker: ", e.what());
    }
    
    LOG_INFO("[SessionManager] Session ", session_id, " worker thread terminated");
}
```

#### 2.4.2. 비교 분석

**I/O 모델별 차이:**

- epoll과 io_uring 구현 모두 유사한 세션 관리 구조를 가지고 있으며, 주요 차이점은 각 세션이 사용하는 I/O 모델에 있습니다.
- epoll 구현에서는 각 세션이 EPoll 인스턴스를 사용하고, io_uring 구현에서는 각 세션이 IOUring 인스턴스를 사용합니다.

**로드 밸런싱:**

- 두 구현 모두 라운드 로빈 방식으로 클라이언트를 세션에 할당하여 부하를 분산시킵니다.
- 세션별 워커 스레드를 사용하여 병렬 처리를 지원합니다.

### 2.2.5 리스너 클래스

#### 2.5.1. `Listener`

- **역할:** 클라이언트 연결을 수락하고, 수락된 연결을 세션 매니저에 할당하는 싱글톤 클래스입니다.
- **주요 멤버 및 기능:**
    - `port_`: 리스닝 포트
    - `listening_socket_`: 리스닝 소켓
    - `session_manager_`: 세션 매니저 참조
    - `start()`: 리스닝 시작
    - `processEvents()`: 이벤트 처리
    - `stop()`: 리스닝 중지
- **epoll 버전 코드 예시:**

```cpp
void Listener::processEvents() {
    if (!running_) {
        return;
    }
    
    // 이벤트 대기
    int num_events = epoll_instance_->waitForEvents(100); // 100ms 타임아웃
    
    // 이벤트 처리
    epoll_event events[Listener::MAX_EVENTS];
    int event_count = epoll_instance_->getEvents(events, Listener::MAX_EVENTS);
    
    for (int i = 0; i < event_count; i++) {
        int fd = events[i].data.fd;
        
        if (fd == listening_socket_->getSocketFd()) {
            // 새 연결 수락
            struct sockaddr_in client_addr;
            socklen_t client_addr_len = sizeof(client_addr);
            
            while (true) { // 모든 대기 중인 연결 수락
                int client_fd = accept(listening_socket_->getSocketFd(), 
                                      (struct sockaddr*)&client_addr, 
                                      &client_addr_len);
                if (client_fd < 0) {
                    if (errno == EAGAIN || errno == EWOULDBLOCK) {
                        break; // 더 이상 수락할 연결이 없음
                    }
                    LOG_ERROR("[Listener] Accept error: ", strerror(errno));
                    break;
                }
                
                // 클라이언트 소켓 처리
                SocketPtr clientSocket = std::make_shared<Socket>(client_fd);
                
                // 세션에 클라이언트 할당
                session_manager_.assignClientToSession(clientSocket);
            }
        }
    }
}
```
- **io_uring 버전 코드 예시:**

```cpp
void Listener::processEvents() {
    if (!io_ring_) {
        LOG_ERROR("[Listener] IOUring is null");
        return;
    }

    // 완료된 이벤트 확인
    unsigned num_cqes = io_ring_->peekCQE(cqes_);
    
    if (num_cqes == 0) {
        // 이벤트가 없으면 대기
        const int result = io_ring_->submitAndWait();
        if (result < 0 && result != -EINTR) {
            LOG_ERROR("[Listener] io_uring_submit_and_wait failed: ", result);
            return;
        }
        num_cqes = io_ring_->peekCQE(cqes_);
    }

    for (unsigned i = 0; i < num_cqes; ++i) {
        io_uring_cqe* cqe = cqes_[i];
        Operation ctx = getContext(cqe);

        if (ctx.op_type == OperationType::ACCEPT) {
            if (cqe->res < 0) {
                LOG_ERROR("[Listener] Accept failed: ", -cqe->res);
            } else {
                int client_fd = cqe->res;
                
                // 클라이언트 소켓 처리
                SocketPtr clientSocket = std::make_shared<Socket>(client_fd);
                
                // 세션에 클라이언트 할당
                session_manager_.assignClientToSession(clientSocket);
                
                // 새로운 ACCEPT 작업 등록
                io_ring_->prepareAccept(listening_socket_->getSocketFd());
            }
        }
    }

    io_ring_->advanceCQ(num_cqes);
    io_ring_->submit();
}
```

**연결 수락 방식:**

- **epoll 구현**: 이벤트 발생 시 `accept()` 시스템 콜을 반복 호출하여 모든 대기 중인 연결을 수락합니다.
- **io_uring 구현**: `multishot_accept`를 사용하여 연결 수락 작업을 한 번만 등록하고, 완료 큐를 통해 새 연결을 처리합니다.

**효율성:**

- **epoll 구현**: 각 연결 수락 시마다 시스템 콜을 호출해야 합니다.
- **io_uring 구현**: 연결 수락 작업을 한 번 등록해두면, 커널이 자동으로 여러 연결을 처리할 수 있습니다.

## 2.3 주요 작업 흐름 비교

### 2.3.1 클라이언트 연결 수락 과정

**epoll 방식:**

1. Listener는 `epoll_wait()`를 호출하여 리스닝 소켓의 이벤트를 기다립니다.
2. 연결 요청이 있으면 `accept()` 시스템 콜을 호출하여 연결을 수락합니다.
3. 연결된 클라이언트 소켓을 비블로킹 모드로 설정합니다.
4. SessionManager를 통해 클라이언트를 적절한 세션에 할당합니다.
5. 세션은 클라이언트 소켓을 epoll 인스턴스에 등록합니다.

**io_uring 방식:**

1. Listener는 리스닝 소켓에 대한 `multishot_accept` 작업을 제출 큐에 등록합니다.
2. 커널은 연결 요청이 있을 때 자동으로 연결을 수락하고, 완료 큐에 결과를 추가합니다.
3. Listener는 완료 큐를 확인하여 새로운 연결을 처리합니다.
4. SessionManager를 통해 클라이언트를 적절한 세션에 할당합니다.
5. 세션은 클라이언트 소켓에 대한 `multishot_recv` 작업을 제출 큐에 등록합니다.

### 2.3.2 데이터 읽기/쓰기 처리

**epoll 방식:**

1. 세션은 `epoll_wait()`를 호출하여 클라이언트 소켓의 이벤트를 기다립니다.
2. 읽기 이벤트가 발생하면 `read()` 시스템 콜을 호출하여 데이터를 읽습니다.
3. 쓰기 이벤트가 발생하면 `write()` 시스템 콜을 호출하여 데이터를 씁니다.
4. 읽기/쓰기 버퍼는 사용자 공간에서 관리되며, 작업 시 커널 공간으로 데이터 복사가 필요합니다.

**io_uring 방식:**

1. 세션은 완료 큐를 확인하여 완료된 읽기/쓰기 작업을 처리합니다.
2. 읽기 작업이 완료되면 데이터를 처리하고, 새로운 읽기 작업을 제출 큐에 등록합니다.
3. 쓰기 작업이 필요하면 제출 큐에 쓰기 작업을 등록합니다.
4. 버퍼는 커널과 공유하는 메모리 영역에서 관리되므로, 데이터 복사 오버헤드가 줄어듭니다.

### 2.3.3 이벤트 처리 루프

**epoll 방식:**

```cpp
while (running) {
    // 이벤트 대기
    int num_events = epoll_wait(epoll_fd, events, MAX_EVENTS, timeout);
    
    // 이벤트 처리
    for (int i = 0; i < num_events; i++) {
        if (events[i].events & EPOLLIN) {
            handleRead(events[i].data.fd);
        }
        if (events[i].events & EPOLLOUT) {
            handleWrite(events[i].data.fd);
        }
        if (events[i].events & (EPOLLRDHUP | EPOLLHUP | EPOLLERR)) {
            handleClose(events[i].data.fd);
        }
    }
}```
**io_uring 방식:**

```cpp
while (running) {
    // 완료된 이벤트 확인
    unsigned num_cqes = io_uring_peek_batch_cqe(ring, cqes, MAX_CQES);
    
    if (num_cqes == 0) {
        // 이벤트가 없으면 대기
        io_uring_submit_and_wait(ring, 1);
        num_cqes = io_uring_peek_batch_cqe(ring, cqes, MAX_CQES);
    }
    
    // 이벤트 처리
    for (unsigned i = 0; i < num_cqes; i++) {
        Operation ctx = getContext(cqes[i]);
        
        switch (ctx.op_type) {
            case OperationType::READ:
                handleRead(cqes[i], ctx);
                break;
            case OperationType::WRITE:
                handleWrite(cqes[i], ctx);
                break;
            case OperationType::ACCEPT:
                handleAccept(cqes[i], ctx);
                break;
            case OperationType::CLOSE:
                handleClose(cqes[i], ctx);
                break;
        }
    }
    
    // 완료 큐 업데이트
    io_uring_cq_advance(ring, num_cqes);
    
    // 새 작업 제출
    io_uring_submit(ring);
}
```